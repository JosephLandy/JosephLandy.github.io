{"componentChunkName":"component---src-templates-post-tsx","path":"/biomotion_mosh/biomotion_mosh/","result":{"data":{"logo":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAABE0lEQVQY03XRv0tCURTA8fuGsiGMGgynhvyxhlMNIrgktaQoYgW2RNLg5NAgTkrR0NKjpR+EDeJki0ODIA39B0Kg+R94n5vbe30vnOERdOHDuefew+FcrlJ/ll4sLH/uuu6153mHZk+01D+LuwTW1cRxctjH1o/jRKRJCnUKsnjBM3mFuIwD3JDHiFFcsU8TB3g0DU+QR/p7NtvmcIWCd1yw/5CGDTygLXmB+y4+JY+jj7qaaF2iWRHniMuET3ilIIk7pHCKEecteeIQGTM9arjHnpmwgpg8fUcavsGm4Ay32EUZl2iihyqO0MExzIt6aqz1Go0C0/k8GLJti8Mwzfoo4os8IhMt+T4gJHEVm74P3PgFag48HMuFl/MAAAAASUVORK5CYII=","width":400,"height":128,"src":"/static/2b5eaa0de166a8b5faebad4955c2200c/497c6/ghost-logo.png","srcSet":"/static/2b5eaa0de166a8b5faebad4955c2200c/497c6/ghost-logo.png 1x"}}},"markdownRemark":{"html":"<p>The BioMotion Lab is a psychology lab formerly based at Queen’s, now at York, that researches how we perceive human motion, developing experiments using motion capture and VR. I did my undergraduate final project with the lab as well as working on a number of projects as a volunteer and employee.</p>\n<p>The BioMotion Lab was in the process of adopting a new motion capture algorithm called MoSh (Motion and Shape) developed at the Max Planck Institute in Tübingen that approximates the body shape of the subject using a parametric model of the human body and is compatible with standard marker based motion capture systems. The algorithm could be used with prior mocap data, and did not require a specific set of marker placements, which was useful for the lab as they had built up a large library of captures. I worked on and built a number of systems in Unity as part of this. </p>\n<h1>Mocap Pipeline Tool - Vertex Selector</h1>\n<p>The first tool I developed was a graphical utility to simplify the pipeline of applying the new algorithm to raw motion capture data. The algorithm required an input file associating the approximate location of motion capture markers with a vertex index on the mesh. I built a program with a GUI for selecting and labelling vertices and generating the file.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2000px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6687ec16fffcf13d0ebd2b5b82c49ec5/d5be6/overview_screenshot.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 54.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAAC3klEQVQozyWS60+aZxjG3/9xydZVtApFDrbIQYvHASo6OwUPSGnaTZzUDdEqwgu8J+DloJ26Lqbb4pqmy/bB2X5r0qRbu+y3R/rhTu4813Nfue7ruqV7O6fcf/yUZO6UhXWDhWSWma/us7xhsPrdEUubjY/v3+gsruvEN0o8zFbIPd4hnd4gn8+jqmqndvcKSFNbLwhtnhPZeolnvog98CXX7Hfwz2YZfXDGUPIHhtaeEEgcElhuEErViW3o5Pd3KRZlZFmmXC6jKApFuYS0VnnFaukvluVLVnZ/ZSiyij+cILTwLXe3f2Pu+3Nmt34h+ugZM5kzIptnJLNt1EqZarWGqqhUKhVarSa6UUPaOv2bzPE7MicfWK+/JjidwD9xl9i6woP6G1L6a5LKBYnSnyTk31kqvCQt/0StanBwUBAqi2iqhq5pVBQN6fl7OP8Hnr2F5x8gs1/CfdtH4fgFT99A++I9R6/g8BJaF//SvvyP2s9/8OPJCQ2z0VFZNarUa3WOjo6Rio1j8vUnxL7Oknh0wGJqh9veOSbjGeLpfaLJTe5ty+T0FhnZEOGJvqxTKOxhmjU0XRH+qaI3qJkqksf/BbeGpnEF41gCK9g8K3hca/QML9HrX8I9EmMgMI3bLyowQ783THQuSS5rkts2Odg/pNlosJc7IRE7Qxq09zB4s4uR4Bi3wg9xTKTon0hiG15hMJxibHQcn6MXn9OKz2XDY7/B/HSEUskQCWti3aYIRnioNpELbSSXrYf+G9fweQMMTqX53BXG5o3zSWSSnugIww4HdoE7+yy4rN3YLJ8SFZhuaGJdlUbDxNANWk2TVruO5LZ14+y9jm/ASTC0gMM7LiyYwhte5M5khAGrBaf1iszC1d+b3Z8xKwg1Te/cXr1eFyoNQdwQPppC4dVAX5cY7GJ0Ykbc4CqBUIzA+DzB4TFcfdc7uEuU2/qRMNoh1Dr3V6tWUSpKJ2VTqP0fS5BzMra8vckAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"overview screenshot\"\n        title=\"overview screenshot\"\n        src=\"/static/6687ec16fffcf13d0ebd2b5b82c49ec5/f97d7/overview_screenshot.png\"\n        srcset=\"/static/6687ec16fffcf13d0ebd2b5b82c49ec5/0eb09/overview_screenshot.png 500w,\n/static/6687ec16fffcf13d0ebd2b5b82c49ec5/1263b/overview_screenshot.png 1000w,\n/static/6687ec16fffcf13d0ebd2b5b82c49ec5/f97d7/overview_screenshot.png 2000w,\n/static/6687ec16fffcf13d0ebd2b5b82c49ec5/d5be6/overview_screenshot.png 2242w\"\n        sizes=\"(max-width: 2000px) 100vw, 2000px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p><img src=\"/6bed666787d2131c24e724d280c4d954/add-vertex.gif\"></p>\n<p>The functionality for vertex selection in the unity editor is not supported in unity and was somewhat difficult to implement, but it’s something I can see being readily useful for building editors for components in other projects. I made vertex selection entirely separate so it can be easily reused. </p>\n<p><img src=\"/e06ab2dcd96cdb9f8672aac53abff3c6/select-vertex.gif\"></p>\n<h1>Animation System</h1>\n<p>I then developed systems and an API for utilizing animations from the new system in Unity with a number of features requested for use in experiments such as support for playback at varying frame rates, displaying just the joint positions as unshaded points with the mesh hidden, and recording subject responses to an animation. </p>\n<p>I also analysed the new motion capture results against joint positions previous motion capture methods.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2000px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/36257dd8148afcc1dd64b54bb6b63b70/c2d10/mosh_compare.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACBUlEQVQoz5WOS28SURiGz2HhrRdo06TGlraY1KTpQk2MRhN1YYhpjKkhMVGTxq2mLFy0irRaWxgQKDDMDDBQYLjVXqhiE1f6B/xXr+c7A8hGrYsn37l874UxxvBPOANnHCfa/dPH2dPnMDd1WZ7v3/RhYNgpzycw5uC8H4f8cJ5x4dH8M4yPubHg9eHalTsYOjVom3L+/w0dDo7rV2/D512C/3kQTx4s4/zo5F+MuNCIMk7XKKY9s3BPX8TklAcT7hmMX5iAZ2YWL268wqW5efgeL+GudxEPbz2Fa2QMTtcIhp2ESzIwOPTbOFXYh9n8hlz9GNnaV5tqG7r1BWr5EMbOERJBC/FwFW31J/LFYxj1NnKdPZqZ0iH8Kxu4t7AIplufoYoHdYc4QJoo7tuUD6Cpe1j3RxBaywphS6KVW9ArRzBEKJnmRRmr9V3wA2w7vwsikWsKGohnu9TlWyhtYnVTQTCa7O1si0mapLmLVOGTYE9CJVjcqCNm1BDTa/ioV200wkLUEHPLRGKtiMh7076Lv5jYIQ1pKVyG5JsygEkhkSEqiHRRK1C0MiJbBWQ2mlCUAmLZmtyJdjSkpQL9AcwWl3soXdIlKJkSUrEG0m8aCLzTsByI4OWqgrdhzQ4nDQV0QiiA2eKOQR/hzqQGm8kCAsLk9Yc0goqO9WgWoWSxV6Df+Bd25PIFBDwJJAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"mosh compare\"\n        title=\"mosh compare\"\n        src=\"/static/36257dd8148afcc1dd64b54bb6b63b70/f97d7/mosh_compare.png\"\n        srcset=\"/static/36257dd8148afcc1dd64b54bb6b63b70/0eb09/mosh_compare.png 500w,\n/static/36257dd8148afcc1dd64b54bb6b63b70/1263b/mosh_compare.png 1000w,\n/static/36257dd8148afcc1dd64b54bb6b63b70/f97d7/mosh_compare.png 2000w,\n/static/36257dd8148afcc1dd64b54bb6b63b70/c2d10/mosh_compare.png 2562w\"\n        sizes=\"(max-width: 2000px) 100vw, 2000px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The BioMotion Lab is a psychology lab formerly based at Queen’s, now at York, that researches how we perceive human motion, developing experiments using motion capture and VR. I did my undergraduate final project with the lab as well as working on a number of projects as a volunteer and employee."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The BioMotion Lab was in the process of adopting a new motion capture algorithm called MoSh (Motion and Shape) developed at the Max Planck Institute in Tübingen that approximates the body shape of the subject using a parametric model of the human body and is compatible with standard marker based motion capture systems. The algorithm could be used with prior mocap data, and did not require a specific set of marker placements, which was useful for the lab as they had built up a large library of captures. I worked on and built a number of systems in Unity as part of this. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Mocap Pipeline Tool - Vertex Selector"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The first tool I developed was a graphical utility to simplify the pipeline of applying the new algorithm to raw motion capture data. The algorithm required an input file associating the approximate location of motion capture markers with a vertex index on the mesh. I built a program with a GUI for selecting and labelling vertices and generating the file."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2000px; "},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/6687ec16fffcf13d0ebd2b5b82c49ec5/d5be6/overview_screenshot.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 54.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAAC3klEQVQozyWS60+aZxjG3/9xydZVtApFDrbIQYvHASo6OwUPSGnaTZzUDdEqwgu8J+DloJ26Lqbb4pqmy/bB2X5r0qRbu+y3R/rhTu4813Nfue7ruqV7O6fcf/yUZO6UhXWDhWSWma/us7xhsPrdEUubjY/v3+gsruvEN0o8zFbIPd4hnd4gn8+jqmqndvcKSFNbLwhtnhPZeolnvog98CXX7Hfwz2YZfXDGUPIHhtaeEEgcElhuEErViW3o5Pd3KRZlZFmmXC6jKApFuYS0VnnFaukvluVLVnZ/ZSiyij+cILTwLXe3f2Pu+3Nmt34h+ugZM5kzIptnJLNt1EqZarWGqqhUKhVarSa6UUPaOv2bzPE7MicfWK+/JjidwD9xl9i6woP6G1L6a5LKBYnSnyTk31kqvCQt/0StanBwUBAqi2iqhq5pVBQN6fl7OP8Hnr2F5x8gs1/CfdtH4fgFT99A++I9R6/g8BJaF//SvvyP2s9/8OPJCQ2z0VFZNarUa3WOjo6Rio1j8vUnxL7Oknh0wGJqh9veOSbjGeLpfaLJTe5ty+T0FhnZEOGJvqxTKOxhmjU0XRH+qaI3qJkqksf/BbeGpnEF41gCK9g8K3hca/QML9HrX8I9EmMgMI3bLyowQ783THQuSS5rkts2Odg/pNlosJc7IRE7Qxq09zB4s4uR4Bi3wg9xTKTon0hiG15hMJxibHQcn6MXn9OKz2XDY7/B/HSEUskQCWti3aYIRnioNpELbSSXrYf+G9fweQMMTqX53BXG5o3zSWSSnugIww4HdoE7+yy4rN3YLJ8SFZhuaGJdlUbDxNANWk2TVruO5LZ14+y9jm/ASTC0gMM7LiyYwhte5M5khAGrBaf1iszC1d+b3Z8xKwg1Te/cXr1eFyoNQdwQPppC4dVAX5cY7GJ0Ykbc4CqBUIzA+DzB4TFcfdc7uEuU2/qRMNoh1Dr3V6tWUSpKJ2VTqP0fS5BzMra8vckAAAAASUVORK5CYII='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"overview screenshot","title":"overview screenshot","src":"/static/6687ec16fffcf13d0ebd2b5b82c49ec5/f97d7/overview_screenshot.png","srcSet":["/static/6687ec16fffcf13d0ebd2b5b82c49ec5/0eb09/overview_screenshot.png 500w","/static/6687ec16fffcf13d0ebd2b5b82c49ec5/1263b/overview_screenshot.png 1000w","/static/6687ec16fffcf13d0ebd2b5b82c49ec5/f97d7/overview_screenshot.png 2000w","/static/6687ec16fffcf13d0ebd2b5b82c49ec5/d5be6/overview_screenshot.png 2242w"],"sizes":["(max-width:","2000px)","100vw,","2000px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n    "}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/6bed666787d2131c24e724d280c4d954/add-vertex.gif"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The functionality for vertex selection in the unity editor is not supported in unity and was somewhat difficult to implement, but it’s something I can see being readily useful for building editors for components in other projects. I made vertex selection entirely separate so it can be easily reused. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"/e06ab2dcd96cdb9f8672aac53abff3c6/select-vertex.gif"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Animation System"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I then developed systems and an API for utilizing animations from the new system in Unity with a number of features requested for use in experiments such as support for playback at varying frame rates, displaying just the joint positions as unshaded points with the mesh hidden, and recording subject responses to an animation. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I also analysed the new motion capture results against joint positions previous motion capture methods."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 2000px; "},"children":[{"type":"text","value":"\n      "},{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/36257dd8148afcc1dd64b54bb6b63b70/c2d10/mosh_compare.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 58.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACBUlEQVQoz5WOS28SURiGz2HhrRdo06TGlraY1KTpQk2MRhN1YYhpjKkhMVGTxq2mLFy0irRaWxgQKDDMDDBQYLjVXqhiE1f6B/xXr+c7A8hGrYsn37l874UxxvBPOANnHCfa/dPH2dPnMDd1WZ7v3/RhYNgpzycw5uC8H4f8cJ5x4dH8M4yPubHg9eHalTsYOjVom3L+/w0dDo7rV2/D512C/3kQTx4s4/zo5F+MuNCIMk7XKKY9s3BPX8TklAcT7hmMX5iAZ2YWL268wqW5efgeL+GudxEPbz2Fa2QMTtcIhp2ESzIwOPTbOFXYh9n8hlz9GNnaV5tqG7r1BWr5EMbOERJBC/FwFW31J/LFYxj1NnKdPZqZ0iH8Kxu4t7AIplufoYoHdYc4QJoo7tuUD6Cpe1j3RxBaywphS6KVW9ArRzBEKJnmRRmr9V3wA2w7vwsikWsKGohnu9TlWyhtYnVTQTCa7O1si0mapLmLVOGTYE9CJVjcqCNm1BDTa/ioV200wkLUEHPLRGKtiMh7076Lv5jYIQ1pKVyG5JsygEkhkSEqiHRRK1C0MiJbBWQ2mlCUAmLZmtyJdjSkpQL9AcwWl3soXdIlKJkSUrEG0m8aCLzTsByI4OWqgrdhzQ4nDQV0QiiA2eKOQR/hzqQGm8kCAsLk9Yc0goqO9WgWoWSxV6Df+Bd25PIFBDwJJAAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n  "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"alt":"mosh compare","title":"mosh compare","src":"/static/36257dd8148afcc1dd64b54bb6b63b70/f97d7/mosh_compare.png","srcSet":["/static/36257dd8148afcc1dd64b54bb6b63b70/0eb09/mosh_compare.png 500w","/static/36257dd8148afcc1dd64b54bb6b63b70/1263b/mosh_compare.png 1000w","/static/36257dd8148afcc1dd64b54bb6b63b70/f97d7/mosh_compare.png 2000w","/static/36257dd8148afcc1dd64b54bb6b63b70/c2d10/mosh_compare.png 2562w"],"sizes":["(max-width:","2000px)","100vw,","2000px"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;","loading":"lazy"},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n    "}]}]}],"data":{"quirksMode":false}},"excerpt":"The BioMotion Lab is a psychology lab formerly based at Queen’s, now at York, that researches how we perceive human motion, developing…","timeToRead":2,"frontmatter":{"title":"BioMotion Lab Animation System","userDate":"24 October 2020","date":"2020-10-24","tags":["Unity","3d","animation"],"excerpt":null,"github":null,"website":null,"image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAABYlAAAWJQFJUiTwAAACEUlEQVQoz51Q30/TYBTt2u1NEARmHcSg0RCCyRbQhUAiPLEXfNDog48+++CPAB2MMdau61y3dt3YZmGwsUkg8QE1Uf+84/2+bstIjCE+nNz79dxz7j0VBEHA/8DvD0AUpb9x/xbeeziL26G7vPf5fP3v4YVFjIyOXd+wJ56ZiyAoh65wwzdHsLy6BnlyGj5RpEvF6104EZSxsvYco+Myf98YGsatsQnMP1nE0koM4ehTRB4vYTwodzV0hOT3Q5IYJA6xW9mAfCeE2PpLxJ69QmQhivsPZujaSQyRcXR5FfLUNF3ngz8Q4Il4qoRexk6mhG3NRly1oKSLUPYL2EqZvL6LZ5AgPmlU8GFbx3t6K+kC9vIu3rzdwuyjMD+in6ze+YFa+zvhG6qnDJc4aF3y6hx/xa7uwKy2OVenOffsJ+/VfBW2e4bGxW++bP3Fa8ihKQhm7QsJOsiT6NMBwylylRavunWEjYSGTNH1uIrH6XYDWqGObOkY9uEFX350/ov3wuBgrszQhEFgb9WsQ9nLEt9CnhawpRqZp83P1HeQoYVszigzvg3LPYfAxIbTRNY58UBbOahPGWUks2XsGlVs7luIaw6JT+ifO1BUBx+TJv37EjSrwRMxU6FnoPdAcRgyhFyliWSuhs2UhY2UZ8iuUguuV4uHXDuYStDtqyZ9kCDbXcCq4Xg9i8uM9F6SgUQG4Q+IkOA8yCcjZwAAAABJRU5ErkJggg==","aspectRatio":1.7032967032967032,"src":"/static/2ad8d83a173a98d464495299ac9375c8/b4649/MoSh_image.png","srcSet":"/static/2ad8d83a173a98d464495299ac9375c8/c5c6c/MoSh_image.png 930w,\n/static/2ad8d83a173a98d464495299ac9375c8/fe828/MoSh_image.png 1860w,\n/static/2ad8d83a173a98d464495299ac9375c8/b4649/MoSh_image.png 2856w","sizes":"(max-width: 2856px) 100vw, 2856px"}}}}},"relatedPosts":{"totalCount":3,"edges":[{"node":{"id":"80d854f5-98cc-5b24-8dc0-fea30d066593","timeToRead":2,"excerpt":"The BioMotion Lab is a psychology lab formerly based at Queen’s, now at York, that researches how we perceive human motion, developing…","frontmatter":{"title":"BioMotion Lab Animation System","date":"2020-10-24"},"fields":{"slug":"/biomotion_mosh/biomotion_mosh/"}}},{"node":{"id":"e9bc3e0c-7229-55ee-8732-51282eeb4182","timeToRead":1,"excerpt":"In October 2019 I participated in Hack for Heritage, an AR/VR hackathon in Kingston Ontario themed around projects that preserve, reflect or…","frontmatter":{"title":"Hack4Heritage VR Project","date":"2019-10-28"},"fields":{"slug":"/hack4heritage/hack4heritage/"}}},{"node":{"id":"0fd26fa2-e11f-56d2-bbb9-9354bbb7955d","timeToRead":1,"excerpt":"Unity Animation Editor This project implements simplified keyframe animation on a timeline to edit animations in Unity’s .anim format at…","frontmatter":{"title":"Unity Animation Tool","date":"1929-12-12T10:00:00.001Z"},"fields":{"slug":"/unity_animator/unity_animator/"}}}]}},"pageContext":{"slug":"/biomotion_mosh/biomotion_mosh/","prev":{"excerpt":"This is a sword I made to take to two large music festivals in the summer of 2019. The cross guard and housing for the electronics were 3d…","timeToRead":2,"frontmatter":{"title":"3D Printed LED Sword","tags":["Electronics","3d Printing"],"date":"2019-12-12T10:00:00.001Z","draft":null,"excerpt":null,"website":null,"github":null,"image":{"childImageSharp":{"fluid":{"aspectRatio":1.24,"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD90lEQVQ4yzWUS28bVRiGvUEpSdqq11SBllLAJWnipLGT2PHdHl/Hd4/jS51MHDtOmgRiN73k0tCiQpVKINqmQqhsKK1YsEFdVEh0wYJdFwixYsGGJb/i4RunLF7NzDnzPfOe77xnTHvPnvP4p5c8/fVPXOEcSnqG4vInTC9ui7aYbm5RXtpCLbf45ofvefnbU8LlFaKNNeK5JuFUjUD8Er7wNO5gDtOt+99x+8ETbj76Ebs/QThfoyAwbWGDvKH6DbT6daICvLN7j79/30ObXaFSWyWhNYmk5ggawEhRgHlM7VtfStEm1fZdpgIqseIimjjTmvvAnMDy89dQqy2WWzv8++oh9YUVFiuXyRUWCBlA9TVQEWBr5x53n/xMffsrxl0K6qUVCksGcJNc40YHmBVgcraNNnedf37Z4+b6KqXMIqVcXYB6Z8leAboM4MbdB7x49RfzN3YZc/hI6S1xuCnL3gdm56+Tq62j1drES2v88eQhj29u4M9eJqhfxZuWHsbKeDpA6WFteZ16c5WsFFgdfpICzIorA5YxrvNXCdW2sBfXcWnLPLvzNS82P8OnX+Ns6iNc8Sp+AbrCBaaCWUzl2SbVUp5IoYbVGUKdWSMljjKyzHTtGpm5Kyj6JsciLfq8M5zObJL1FuizpzEHKgTUKi5x55Tl2v1pTNXmGlqlhjtexOaOEp9tkdCvkJpbJyF9i8+0SFbFibZKv1LndGSZfmcRjyeKNyn9S8zgjhRwiju7PyXA1qc0tu9jC6aY8CWI6W1i1bV9XfqYWGVVIrNCeHqRjDjemGuw4LKiTw5itjiwOFXGfDmsnjRWt4qpufMFt799jmUygEPJEBGAEdyIASktEy4udWD+3ALZUpNtvUZbsRMx99F1oJueI6foPTMqusjB0yOY1j5/hH51lwtjTuxKFqWwRFACqxT2ZdwH8w3Z1TqB7Dx6Kk/JPsLA2yd4o6ub3sNH6T32Fr0nztB9/CymfKMthQtcuOjAEcqJk3qn2J9rEBAZz77MvMRjDk9qFm+8zPCEl75TJzl46Ahdb/ZwoPsg3YdPdmTyx6WZAhqw2OSalSIdT1rvAP5XZywpzZcT4YhWODuhctRs4/i7w5w7b6H/HTNHjvfTc+goJqs3ykWJi3nAwrg/iUN2bCpawinZcsoJcL2WM14RlfHJ/dB4iO4xlZ73rIxI78clLiMOhUGrG9OoRGXI5uL980OyUzGZlN2Wv8ZkSHIV1nBIYA3ZDYU0fGqZD5OrnLKGGJxUGJ0KMyKy2BWGJ/2Yhu0BPhgY4Zx5UAYDjLoijHlUbL4kNvnyeCAtH8iIskwEMlh9KZlPMGa85451YMP2IEMTfnHo4T9Bim4bvO1+JQAAAABJRU5ErkJggg==","sizes":"(max-width: 1600px) 100vw, 1600px","src":"/static/fe6f6f01ff6309fbfffd855a96f7067c/5707d/sword_held_cropped.png","srcSet":"/static/fe6f6f01ff6309fbfffd855a96f7067c/c5c6c/sword_held_cropped.png 930w,\n/static/fe6f6f01ff6309fbfffd855a96f7067c/5707d/sword_held_cropped.png 1600w"}}}},"fields":{"layout":"post","slug":"/LED_sword/sword/"}},"next":null,"primaryTag":"Unity"}},"staticQueryHashes":["138661842"]}